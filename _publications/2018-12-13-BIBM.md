---
title: "Automated Pancreas Segmentation Using Recurrent Adversarial Learning"
collection: Conference Articles
permalink: /publication/2018-12-13-BIBM
excerpt: ''
date: 2018-12-13
venue: '2018 IEEE International Conference on Bioinformatics and Biomedicine (BIBM)'
paperurl: ''
citation: 'Yang Ning, <b>Zhongyi Han</b>, Li Zhong, Caiming Zhang, &quot;Automated Pancreas Segmentation Using Recurrent Adversarial Learning&quot;. <i>2018 IEEE International Conference on Bioinformatics and Biomedicine (BIBM)</i>, 2018, pp.927-934.'
---
Abstract
===
Automated pancreas segmentation based on computed tomography (CT) is one extensively useful technique of computer-aided detection for pancreas cancer diagnosis and prognosis. However, it is very challenging in practice because the pancreas, the small, soft and flexible abdominal organ, has very high anatomical variability which leads existing studies to suffer from an unsatisfactory performance. In this paper, we propose a new automated pancreas segmentation framework: Recurrent Adversarial Learning based on Generative Adversarial Network (Pancreas-GAN) to tackle this challenge. Pancreas-GAN consists of three novel modules: 1) a dilated convolutions auto-encoder module (DCAE) not only explicitly maintains global resolution of CT images but also enlarges the receptive field of filters to effectively incorporate larger context without increasing the computation complexity; 2) a local long short-term memory module (Local-LSTM) can capture the contextual segmentation correlation across neighboring image patches for boosting precise boundary segmentation; and 3) an adversarial module can constrain the spatial smoothness consistency among successive image slices based on the global distribution constraints, which further boosts the performance of Pancreas-GAN. Extensive experiments are conducted on the CT scans of 80 patients using 4-fold cross-validation and have demonstrated that Pancreas-GAN outperforms the state-of-the-art methods in terms of both the Dice similarity coefficient (DSC) of 88.72% ±3.23 and the pixel-wise accuracy of 95.34%±3.05. This reveals the effectiveness and the potential of our method in the clinical setting.

[Download paper here](https://ieeexplore.ieee.org/abstract/document/8621385)