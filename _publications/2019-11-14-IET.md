---
title: "DRAN: Deep Recurrent Adversarial Network for Automated Pancreas Segmentation"
collection: Journal Articles
permalink: /publication/2019-11-14-IET
excerpt: ''
date: 2019-11-14
venue: 'IET Image Processing'
paperurl: ''
citation: 'Yang Ning, <b>Zhongyi Han</b>, Li Zhong, Caiming Zhang, &quot; DRAN: Deep Recurrent Adversarial Network for Automated Pancreas Segmentation&quot;. <i>IET Image Processing</i>, 2019.'
---
Abstract
===
Automated pancreas segmentation in abdominal computed tomography (CT) scans is of high clinical relevance (i.e. pancreas cancer diagnosis and prognosis), but extremely difficult because the pancreas is a soft, small, and flexible abdominal organ with high anatomical variability, which causes the previous segmentation methods to result in low precision. In this study, the authors present a new deep recurrent adversarial network (DRAN) to tackle this challenge. DRAN contains three steps: (i) preserving global resolution of CT scans and modifying the receptive field of kernel adaptively through a dilated convolution autoencoder module; (ii) modelling contextual spatial correlation between neighbouring CT scan patches benefits from a specially designed local long short-term memory module; and (iii) improving the performance and generalisation by leveraging an adversarial module, which can constrain the spatial smoothness consistency between continuous CT scans based on the long-range spatial interaction. The system is evaluated on a dataset of 80 manually segmented CT volumes, using four-fold cross-validation. Its performance surpasses other state-of-the-art methods, with the Dice similarity coefficient of 89.87±3.17% and pixel-wise accuracy of 95.85±3.04%. Also, they perform a qualitative evaluation by an expert further revealing the effectiveness and potential of their DRAN as a clinical segmentation tool.

[Download paper here](https://digital-library.theiet.org/content/journals/10.1049/iet-ipr.2019.0399)